#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åº”ç”¨è¯Šæ–­è„šæœ¬ - æ£€æŸ¥å„é¡¹æœåŠ¡çŠ¶æ€
"""

import socket
import requests
import subprocess
import sys
import time
import os

def check_port(port, service_name):
    """æ£€æŸ¥ç«¯å£æ˜¯å¦å¼€æ”¾"""
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        result = sock.connect_ex(('localhost', port))
        sock.close()
        if result == 0:
            print(f"âœ… {service_name} (ç«¯å£ {port}) - æ­£åœ¨è¿è¡Œ")
            return True
        else:
            print(f"âŒ {service_name} (ç«¯å£ {port}) - æœªè¿è¡Œ")
            return False
    except Exception as e:
        print(f"âš ï¸  {service_name} (ç«¯å£ {port}) - æ£€æŸ¥å¤±è´¥: {e}")
        return False

def test_api_endpoint(url, service_name):
    """æµ‹è¯•APIç«¯ç‚¹"""
    try:
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            print(f"âœ… {service_name} - æ­£å¸¸å“åº”")
            return True
        else:
            print(f"âš ï¸  {service_name} - å“åº”ç : {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print(f"âŒ {service_name} - è¿æ¥å¤±è´¥")
        return False
    except Exception as e:
        print(f"âš ï¸  {service_name} - é”™è¯¯: {e}")
        return False

def check_ollama():
    """æ£€æŸ¥OllamaæœåŠ¡"""
    try:
        response = requests.get('http://localhost:11434/api/tags', timeout=3)
        if response.status_code == 200:
            models = response.json().get('models', [])
            print(f"âœ… OllamaæœåŠ¡ - æ­£å¸¸è¿è¡Œ ({len(models)} ä¸ªæ¨¡å‹)")
            if models:
                llama_models = [m for m in models if 'llama' in m['name'].lower()]
                if llama_models:
                    print(f"   ğŸ¤– å‘ç°Llamaæ¨¡å‹: {[m['name'] for m in llama_models[:2]]}")
                else:
                    print("   âš ï¸  æœªå‘ç°Llamaæ¨¡å‹")
            return True
        else:
            print("âš ï¸  OllamaæœåŠ¡ - å“åº”å¼‚å¸¸")
            return False
    except Exception as e:
        print(f"âŒ OllamaæœåŠ¡ - æœªè¿è¡Œ: {e}")
        return False

def check_processes():
    """æ£€æŸ¥ç›¸å…³è¿›ç¨‹"""
    print("\nğŸ” æ£€æŸ¥è¿è¡Œè¿›ç¨‹...")
    try:
        # æ£€æŸ¥Pythonè¿›ç¨‹
        result = subprocess.run(['tasklist', '/FI', 'IMAGENAME eq python.exe'], capture_output=True, text=True)
        python_processes = [line for line in result.stdout.split('\n') if 'python.exe' in line.lower()]
        if python_processes:
            print(f"âœ… å‘ç° {len(python_processes)} ä¸ªPythonè¿›ç¨‹")
        else:
            print("âš ï¸  æœªå‘ç°Pythonè¿›ç¨‹")

        # æ£€æŸ¥nodeè¿›ç¨‹
        result = subprocess.run(['tasklist', '/FI', 'IMAGENAME eq node.exe'], capture_output=True, text=True)
        node_processes = [line for line in result.stdout.split('\n') if 'node.exe' in line.lower()]
        if node_processes:
            print(f"âœ… å‘ç° {len(node_processes)} ä¸ªNode.jsè¿›ç¨‹")
        else:
            print("âš ï¸  æœªå‘ç°Node.jsè¿›ç¨‹")

    except Exception as e:
        print(f"âš ï¸  è¿›ç¨‹æ£€æŸ¥å¤±è´¥: {e}")

def main():
    """ä¸»è¯Šæ–­å‡½æ•°"""
    print("=" * 60)
    print("ğŸ”§ æƒ…æ™¯èƒŒå•è¯å°ç¨‹åº - ç³»ç»Ÿè¯Šæ–­")
    print("=" * 60)

    print("æ£€æŸ¥å„é¡¹æœåŠ¡çŠ¶æ€...\n")

    # æ£€æŸ¥ç«¯å£
    backend_ok = check_port(5000, "åç«¯æœåŠ¡")
    frontend_ok = check_port(3001, "å‰ç«¯æœåŠ¡")

    print()

    # æµ‹è¯•API
    if backend_ok:
        api_ok = test_api_endpoint('http://localhost:5000/api/health', 'åç«¯å¥åº·æ£€æŸ¥')
        vocab_ok = test_api_endpoint('http://localhost:5000/api/vocabulary/daily?count=1', 'å•è¯API')
    else:
        api_ok = vocab_ok = False

    print()

    # æ£€æŸ¥Ollama
    ollama_ok = check_ollama()

    print()

    # æ£€æŸ¥è¿›ç¨‹
    check_processes()

    print("\n" + "=" * 60)

    # æä¾›è§£å†³æ–¹æ¡ˆ
    if not backend_ok:
        print("ğŸ”§ åç«¯æœåŠ¡æœªè¿è¡Œ:")
        print("   cd vocabulary_story_app/backend")
        print("   python app.py")
        print()

    if not frontend_ok:
        print("ğŸ”§ å‰ç«¯æœåŠ¡æœªè¿è¡Œ:")
        print("   cd vocabulary_story_app/frontend")
        print("   npm start")
        print()

    if not ollama_ok:
        print("ğŸ”§ Ollamaæœªè¿è¡Œ:")
        print("   1. å®‰è£…Ollama: https://ollama.ai/download")
        print("   2. å¯åŠ¨æœåŠ¡: ollama serve")
        print("   3. ä¸‹è½½æ¨¡å‹: ollama pull llama3.2")
        print()

    if backend_ok and frontend_ok and api_ok and ollama_ok:
        print("ğŸ‰ æ‰€æœ‰æœåŠ¡æ­£å¸¸è¿è¡Œï¼")
        print("ğŸŒ æ‰“å¼€æµè§ˆå™¨è®¿é—®: http://localhost:3001")
    else:
        print("âš ï¸  å‘ç°é—®é¢˜ï¼Œè¯·æŒ‰ç…§ä¸Šè¿°å»ºè®®ä¿®å¤")

    print("=" * 60)

if __name__ == "__main__":
    main()
